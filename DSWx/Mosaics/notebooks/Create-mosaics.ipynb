{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to create mosaics of the DSWx product that are relatively cloud free over different parts of the world. In this notebook, we demonstrate generating these mosaics over Australia and California. The shapefile for CA was obtained [from here](https://data.ca.gov/dataset/ca-geographic-boundaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIS imports\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.warp import transform_bounds, calculate_default_transform, reproject, Resampling\n",
    "from shapely import Polygon\n",
    "import fiona\n",
    "\n",
    "# misc imports\n",
    "from pystac_client import Client\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "\n",
    "# web imports\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of CMR service\n",
    "STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "# Setup PySTAC client\n",
    "provider_cat = Client.open(STAC_URL)\n",
    "catalog = Client.open(f'{STAC_URL}/POCLOUD/')\n",
    "collections = [\"OPERA_L3_DSWX-HLS_PROVISIONAL_V1\"]\n",
    "\n",
    "# We would like to create mosaics for April 2023\n",
    "date_range = \"2023-04-01/2023-04-30\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSWx mosaics over Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all relevant mosaics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the geometry for Australia to retrieve bounding boxes for our search\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "australia_shape = world[world['name']=='Australia']\n",
    "bbox = australia_shape.iloc[0].geometry.bounds\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = {\n",
    "    'bbox' : bbox, \n",
    "    'collections': collections,\n",
    "    'datetime' : date_range,\n",
    "    # querying by cloud cover does not work (04/27/23)\n",
    "    # We will instead filter results by parsing the associated XML files for each granule\n",
    "    # 'query':{\n",
    "    #     'eo:cloud_cover':{\n",
    "    #         'lt': 10    \n",
    "    #     },\n",
    "    # }\n",
    "}\n",
    "\n",
    "search = catalog.search(**opts)\n",
    "items = search.get_all_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for cloud cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_cloud_cover(item, threshold=10):\n",
    "    xml_url = item.assets['metadata'].href\n",
    "    response = urlopen(xml_url)\n",
    "    data_json = json.loads(response.read()) # the XML files are formatted as JSONs (?!), so we use a JSON reader\n",
    "\n",
    "    for item in data_json['AdditionalAttributes']:\n",
    "        if item['Name'] == 'PercentCloudCover':\n",
    "            break\n",
    "    c_cover = int(item['Values'][0])\n",
    "    if c_cover<=threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "filtered_items = list(filter(filter_by_cloud_cover, items))\n",
    "print(len(filtered_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_granule(item):\n",
    "    return item.assets['0_B01_WTR'].href\n",
    "filtered_urls = list(map(return_granule, filtered_items))\n",
    "print(len(filtered_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('../data/australia')\n",
    "if not output_path.exists():\n",
    "    output_path.mkdir(parents=True)\n",
    "\n",
    "def download_data(file_list):\n",
    "    for f in file_list:\n",
    "        try:\n",
    "            os.system(f\"wget {f} -nc -q -P {output_path}\") # don't clobber, and download quietly\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can parallelize the downloads\n",
    "url_chunks = np.array_split(filtered_urls, 30)\n",
    "with Pool() as pool:\n",
    "    _ = pool.map(download_data, url_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfiles = len(list(output_path.glob('OPERA*.tif')))\n",
    "print(nfiles)\n",
    "\n",
    "# DSWx files have colormaps associated with them. Let's save it for later use\n",
    "with rasterio.open(list(output_path.glob('OPERA*.tif'))[0]) as ds:\n",
    "    dswx_colormap = ds.colormap(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize and mosaic granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_by_crs = defaultdict(list)\n",
    "for f in [f for f in output_path.iterdir() if f.is_dir()]:\n",
    "    files_by_crs[f.name] = list(f.glob(\"OPERA*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize downloaded into folders by CRS \n",
    "files_by_crs = defaultdict(list)\n",
    "for i, f in enumerate(list(output_path.glob('*.tif'))):\n",
    "    with rasterio.open(f) as ds:\n",
    "        files_by_crs[ds.profile['crs'].to_string()].append(f)\n",
    "\n",
    "def organize_by_crs(crs, file_list):\n",
    "    current_output_path = output_path/crs\n",
    "    if not current_output_path.exists():\n",
    "        current_output_path.mkdir()\n",
    "    \n",
    "    for f in file_list:\n",
    "        f.rename(current_output_path/f.name)\n",
    "\n",
    "_ = list(map(organize_by_crs, files_by_crs.keys(), files_by_crs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take a list of files in the same CRS and mosaic them, and then reproject it to \n",
    "# EPSG:4326.\n",
    "\n",
    "def process_file_batch(epsg_code, file_batch, output_filename, resolution_reduction_factor = 2):\n",
    "    dst_crs = 'EPSG:4326'\n",
    "    merged_img, merged_transform = merge(file_batch, method='min')\n",
    "    merged_output_bounds = rasterio.transform.array_bounds(merged_img.shape[-2], merged_img.shape[-1] , merged_transform)\n",
    "\n",
    "    kwargs = {\n",
    "        \"src_crs\": epsg_code, \n",
    "        \"dst_crs\": dst_crs, \n",
    "        \"width\":merged_img.shape[-1], \n",
    "        \"height\": merged_img.shape[-2], \n",
    "        \"left\": merged_output_bounds[0],\n",
    "        \"bottom\": merged_output_bounds[1],\n",
    "        \"right\": merged_output_bounds[2],\n",
    "        \"top\": merged_output_bounds[3],\n",
    "        \"dst_width\": merged_img.shape[-1]//resolution_reduction_factor, \n",
    "        \"dst_height\":merged_img.shape[-2]//resolution_reduction_factor  \n",
    "    }\n",
    "    \n",
    "    dst_transform, width, height = calculate_default_transform(**kwargs)\n",
    "\n",
    "    with rasterio.open(file_batch[0]) as src:\n",
    "        dst_kwargs = src.profile.copy()\n",
    "        dst_kwargs.update({\n",
    "            'height':height,\n",
    "            'width':width,\n",
    "            'transform':dst_transform,\n",
    "            'crs':dst_crs\n",
    "        })\n",
    "        \n",
    "        with rasterio.open(output_filename, 'w', **dst_kwargs) as dst:\n",
    "            reproject(\n",
    "                source = merged_img, \n",
    "                destination = rasterio.band(dst, 1), \n",
    "                src_transform = merged_transform,\n",
    "                dst_transform = dst_transform,\n",
    "                src_crs = src.crs,\n",
    "                dst_crs = dst_crs,\n",
    "                resampling=Resampling.nearest\n",
    "            )\n",
    "            dst.write_colormap(1, dswx_colormap)\n",
    "\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mosaicking a large number of files in one attempt will be time and memory intensive.\n",
    "# Instead, we can mosaic chunks in parallel, and reduce the resolution of each mosaic by a factor of 2\n",
    "# The mosaics generated in this step can then be subsequently combined similarly\n",
    "\n",
    "for key in files_by_crs.keys():\n",
    "    mosaic_folder = (output_path/key/'mosaics')\n",
    "    mosaic_folder.mkdir(parents=True, exist_ok=True)\n",
    "    filenames = list((output_path/key).glob('*.tif'))\n",
    "    filename_chunks = np.array_split(filenames, 30)\n",
    "    \n",
    "    output_filename = 'temp_{}_{}.tif'\n",
    "\n",
    "    function_inputs = []\n",
    "    function_inputs = [(key, chunk, mosaic_folder/output_filename.format(key, str(count).zfill(4))) for count, chunk in enumerate(filename_chunks) if len(chunk) > 0]\n",
    "    \n",
    "    with Pool() as pool:\n",
    "        output_files = pool.starmap(process_file_batch, function_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate final mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_list = []\n",
    "for folder in output_path.iterdir():\n",
    "    if folder.name == 'outputs':\n",
    "        pass\n",
    "    for file in list((folder /'mosaics').glob('*.tif')):\n",
    "        mosaic_list.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mosaic_path = Path('../data/australia/outputs')\n",
    "if not final_mosaic_path.exists():\n",
    "    final_mosaic_path.mkdir()\n",
    "process_file_batch('EPSG:4326', mosaic_list, Path(final_mosaic_path / 'final_mosaic.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSWx mosaics over CA/NV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_state = fiona.open('../data/shapefiles/california_state/CA_State_TIGER2016.shp')\n",
    "ca_bounds = ca_state.bounds\n",
    "if ca_state.crs is not CRS.from_epsg(4326):\n",
    "    ca_bounds = transform_bounds(ca_state.crs, CRS.from_epsg(4326), *ca_bounds)\n",
    "print(ca_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all relevant mosaics, and filter for cloud cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for DSWx over CA\n",
    "# we can modify the search to intersect with our shape instead of using bounding boxes to restrict results to only CA\n",
    "STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "# Setup PySTAC client\n",
    "provider_cat = Client.open(STAC_URL)\n",
    "catalog = Client.open(f'{STAC_URL}/POCLOUD/')\n",
    "collections = [\"OPERA_L3_DSWX-HLS_PROVISIONAL_V1\"]\n",
    "\n",
    "date_range = \"2023-04-01/2023-04-30\"\n",
    "\n",
    "opts = {\n",
    "    'bbox' : ca_bounds, \n",
    "    'collections': collections,\n",
    "    'datetime' : date_range,\n",
    "    # querying by cloud cover does not work (04/27/23)\n",
    "    # We will instead filter results by parsing the associated XML files for each granule\n",
    "    # 'query':{\n",
    "    #     'eo:cloud_cover':{\n",
    "    #         'lt': 10    \n",
    "    #     },\n",
    "    # }\n",
    "}\n",
    "\n",
    "search = catalog.search(**opts)\n",
    "items = search.get_all_items()\n",
    "\n",
    "filtered_items = list(filter(filter_by_cloud_cover, items))\n",
    "print(len(filtered_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_urls = list(map(return_granule, filtered_items))\n",
    "print(len(filtered_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('../data/california')\n",
    "files_by_crs = defaultdict(list)\n",
    "for f in [f for f in output_path.iterdir() if f.is_dir()]:\n",
    "    files_by_crs[f.name] = list(f.glob(\"OPERA*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('../data/california')\n",
    "if not output_path.exists():\n",
    "    output_path.mkdir(parents=True)\n",
    "\n",
    "# We can parallelize the downloads\n",
    "url_chunks = np.array_split(filtered_urls, 30)\n",
    "with Pool() as pool:\n",
    "    _ = pool.map(download_data, url_chunks)\n",
    "\n",
    "nfiles = len(list(output_path.glob('*.tif')))\n",
    "print(nfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize and mosaic granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize downloaded into folders by CRS \n",
    "files_by_crs = defaultdict(list)\n",
    "for i, f in enumerate(list(output_path.glob('*.tif'))):\n",
    "    with rasterio.open(f) as ds:\n",
    "        files_by_crs[ds.profile['crs'].to_string()].append(f)\n",
    "\n",
    "_ = list(map(organize_by_crs, files_by_crs.keys(), files_by_crs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSWx files have colormaps associated with them. Let's save it for later use\n",
    "with rasterio.open(files_by_crs[list(files_by_crs.keys())[0]][0]) as ds:\n",
    "    dswx_colormap = ds.colormap(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in files_by_crs.keys():\n",
    "    mosaic_folder = (output_path/key/'mosaics')\n",
    "    mosaic_folder.mkdir(parents=True, exist_ok=True)\n",
    "    filenames = list((output_path/key).glob('*.tif'))\n",
    "    filename_chunks = np.array_split(filenames, 30)\n",
    "    \n",
    "    output_filename = 'temp_{}_{}.tif'\n",
    "\n",
    "    function_inputs = []\n",
    "    function_inputs = [(key, chunk, mosaic_folder/output_filename.format(key, str(count).zfill(4)), 1) for count, chunk in enumerate(filename_chunks) if len(chunk) > 0]\n",
    "    \n",
    "    with Pool() as pool:\n",
    "        output_files = pool.starmap(process_file_batch, function_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_list = []\n",
    "for folder in output_path.iterdir():\n",
    "    if folder.name == 'outputs':\n",
    "        pass\n",
    "    for file in list((folder /'mosaics').glob('*.tif')):\n",
    "        mosaic_list.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate final mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mosaic_path = Path('../data/california/outputs')\n",
    "if not final_mosaic_path.exists():\n",
    "    final_mosaic_path.mkdir()\n",
    "process_file_batch('EPSG:4326', mosaic_list, Path(final_mosaic_path / 'final_mosaic.tif'), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
