{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing change in reservoir surface water extent using the OPERA DSWx product with a time slider\n",
    "---\n",
    "\n",
    "**This notebook serves as a visualization tool using DSWx B01_WTR to illustrate change of Lake Mead, NV during 2022.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook dependencies\n",
    "import os\n",
    "import math\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import rioxarray as rioxr\n",
    "import hvplot.xarray\n",
    "import geoviews as gv\n",
    "import pyproj\n",
    "from pyproj import Proj\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import holoviews as hv\n",
    "import panel.widgets as pnw\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "from bokeh.models import FixedTicker\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['AWS_NO_SIGN_REQUEST'] = 'YES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Data Information Input**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, the user should specify the:\n",
    "* Dates of interest <br>\n",
    "* Data directory<br>\n",
    "* Band of interest<br>\n",
    "* Path to shapefile to create mask<br><br>\n",
    "\n",
    "**<font color='red'>Note: The cell below is the only code in the notebook that should be modified. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access all 2022 provisional products from S3 bucket\n",
    "data_dir = [match for match in sorted(open(\"aux_files/T11SQA_manifest.txt\",\"r\").read().split(\"\\n\")) if '2022' in match]\n",
    "for i,path in enumerate(data_dir):\n",
    "   if path != '': # discard empty entries\n",
    "       if path[91] == 'L': # Landsat 8 filenames\n",
    "           data_dir[i] = path+path[32:101]+'_'\n",
    "       if path[91] == 'S': #Sentinel-2 filenames\n",
    "           data_dir[i] = path+path[32:102]+'_'\n",
    "# Landsat filenames are 1 character shorter than Sentinel-2 filenames\n",
    "\n",
    "# Extract date information from filename\n",
    "dates = [path[57:65] for path in data_dir]\n",
    "\n",
    "# Change this to the desired band for visualization\n",
    "band = 'B01_WTR'\n",
    "\n",
    "# Path to shapefile used to create mask of pixels close to Lake Mead\n",
    "shapepath = 'aux_files/bufferlakebnds/bufferlakebnds.shp'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color='red'> -- Do not modify any of the code below -- </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def file_dataframe(data_dir:str,datelist:str):\n",
    "    '''\n",
    "    Returns dataframe with data_dir to DSWx layers for a given list of dates.\n",
    "        Parameters:\n",
    "                data_dir (str): Working directory for each date\n",
    "                datelist (str): List of dates\n",
    "        Returns:\n",
    "                dswx_file_df (Pandas DataFrame): List of data_dir to layer for each date\n",
    "    '''\n",
    "    fileDF = []\n",
    "    for i,date in enumerate(dates):\n",
    "        paths = f\"{data_dir[i]}%s.tif\"\n",
    "        B01_WTR = paths%'B01_WTR'\n",
    "        B02_BWTR = paths%'B02_BWTR'\n",
    "        B03_CONF = paths%'B03_CONF'\n",
    "        B04_DIAG = paths%'B04_DIAG.tif'\n",
    "        B05_WTR_1 = paths%'B05_WTR-1.tif'\n",
    "        B06_WTR_2 = paths%'B06_WTR-2.tif'\n",
    "        B07_LAND = paths%'B07_LAND.tif'\n",
    "        B08_SHAD = paths%'*B08_SHAD.tif'\n",
    "        B09_CLOUD = paths%'*B09_CLOUD.tif'\n",
    "        B10_DEM = paths%'DEM.tif'\n",
    "        fileDF.append([date,B01_WTR,B02_BWTR,B03_CONF,B04_DIAG,B05_WTR_1,B06_WTR_2,B07_LAND,B08_SHAD,B09_CLOUD,B10_DEM])\n",
    "    fileDF = pd.DataFrame(fileDF,columns = ['Date', 'B01_WTR', 'B02_BWTR', 'B03_CONF', 'B04_DIAG', 'B05_WTR_1', 'B06_WTR_2', \\\n",
    "        'B07_LAND', 'B08_SHAD', 'B09_CLOUD', 'B10_DEM']).astype('string')\n",
    "    return fileDF\n",
    "\n",
    "def stack_layers(files:str,datelist:str):\n",
    "    '''\n",
    "    Returns geocube with one band over time stacked into one multi-dimensional array.\n",
    "            Parameters:\n",
    "                    files (str): data_dir to band for each date\n",
    "                    datelist (list): List of dates\n",
    "            Returns:\n",
    "                    layerStack (xarray Dataset): Geocube with band stacked in time\n",
    "                    crs (int): Coordinate Reference System corresponding to band\n",
    "    '''\n",
    "    layerStack = []; layerS = []; layerStack_ = [];\n",
    "    for i,d in enumerate(datelist):\n",
    "        time = datetime.strptime(d,'%Y%m%d')\n",
    "        if i == 0:\n",
    "            layerStack_ = xr.open_rasterio(files[i])\n",
    "            crs = pyproj.CRS.to_epsg(pyproj.CRS.from_proj4(layerStack_.crs))\n",
    "            layerStack = layerStack_.squeeze(drop=True)\n",
    "            layerStack = layerStack.to_dataset(name='z')\n",
    "            layerStack.coords['time'] = np.array(time)\n",
    "            layerStack = layerStack.rename({'x':'longitude', 'y':'latitude'})\n",
    "            layerStack = layerStack.expand_dims(dim='time')\n",
    "        else:\n",
    "            layerS = xr.open_rasterio(files[i])\n",
    "            layerS = layerS.squeeze(drop=True)\n",
    "            layerS = layerS.to_dataset(name='z')\n",
    "            layerS.coords['time'] = np.array(time)\n",
    "            layerS = layerS.rename({'x':'longitude', 'y':'latitude'})\n",
    "            layerS = layerS.expand_dims(dim='time')\n",
    "            layerStack = xr.concat([layerStack,layerS], dim='time')\n",
    "    return layerStack, crs\n",
    "\n",
    "def buffer_mask(shapefile:str):\n",
    "    '''\n",
    "    Returns masked data based on buffered shapefile.\n",
    "            Parameters:\n",
    "                    shapefile (str): Path to buffered shapefile\n",
    "            Returns:\n",
    "                    masked (xarray Dataset): Geocube of masked data\n",
    "    '''\n",
    "    shp = gpd.read_file(shapefile)\n",
    "    masked = data.rio.clip(shp.geometry)\n",
    "    masked = masked.where(masked['z'] != 255.)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color='red'> -- Do not modify any of the code above -- </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **1. Prepare the Geocube: Create the file dataframe, multidimensional dataset, and mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of paths to bands for each date\n",
    "dswx_file_df = file_dataframe(data_dir,dates)\n",
    "# Inspect the dataframe\n",
    "dswx_file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack dates to create a multidimensional \"geocube\" for chosen band\n",
    "data, crs = stack_layers(dswx_file_df[band], dates)\n",
    "# Inspect the geocube dataset created\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only include pixels near Lake Mead by creating mask from buffered shapefile based on a [2003 USGS shapefile](https://pubs.usgs.gov/of/2009/1150/gis/basemap/lakebndsmeta.htm). This shapefile is created using the optional [prep_shapefile](link) notebook provided in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a masked geocube\n",
    "masked_data = buffer_mask(shapepath)\n",
    "# Inspect the masked dataset\n",
    "masked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. Visualize surface water extent of Lake Mead during 2022**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basemap\n",
    "base = gv.tile_sources.EsriImagery.opts(width=1000, height=1000, padding=0.1)\n",
    "\n",
    "dswxPalette = [\"#2000ff\",\"#04fc04\",\"#ffffff\",\"#ffffff\",\"#ffffff\",\"#ffffff\",\"#ffffff\",\"#ffffff\",\"#7f7f7f\"]\n",
    "\n",
    "masked_data_z = masked_data.z.where(masked_data.z>0)\n",
    "\n",
    "masked_data_slider = masked_data_z.interactive.sel(time=pnw.DiscreteSlider).hvplot(x='longitude', \n",
    "                                                                                       y='latitude', \n",
    "                                                                                       crs=crs, \n",
    "                                                                                       kind='image', \n",
    "                                                                                       rasterize=True, \n",
    "                                                                                       dynamic=True,\n",
    "                                                                                       cmap=dswxPalette, \n",
    "                                                                                       aspect='equal', \n",
    "                                                                                       frame_width=600, \n",
    "                                                                                       frame_height=600).opts(active_tools=['wheel_zoom'],\n",
    "                                                                                                              xlabel='Longitude', \n",
    "                                                                                                              ylabel='Latitude',  \n",
    "                                                                                                              clim=(1,9), \n",
    "                                                                                                              colorbar_opts={'ticker': FixedTicker(ticks=[0, 1, 2, 9])}, \n",
    "                                                                                                              alpha=0.9)\n",
    "masked_data_slider * base"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('opera_app': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "205fae3fe455e9e0e20101222ca8c66fcf772eb94a9e366b20e53a9060420ec0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
