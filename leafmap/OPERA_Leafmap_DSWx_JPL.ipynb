{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Leafmap and Earthaccess to Explore OPERA DSWx-HLS Products. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Leafmap library provides a suite of tools for interactive mapping and visualization in Jupyter Notebooks Leafmap version 0.30.0 and and later offer tools specifically for accessing NASA Earthdata by building on the newly developed NASA Earthaccess library. Earthaccess provides streamlined access to NASA Earthdata and simplifies the authentication and querying process over previously developed approaches. This notebook is designed to leverage tools within Earthaccess and Leafmap to facility easier access and vizualization of OPERA data products for a user-specified area of interest (AOI). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPERA DSWx-HLS info\n",
    "see website https://www.jpl.nasa.gov/go/opera/products/dswx-product-suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import leafmap\n",
    "import rasterio\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "from PIL import Image\n",
    "from shapely import box\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication \n",
    "A [NASA Earthdata Login](https://urs.earthdata.nasa.gov/) account is required to download the data used in this tutorial. You can create an account at the link provided. After establishing an account, the code in the next cell will verify authentication. If this is your first time running the notebook, you will be prompted to enter your Earthdata login credentials, which will be saved in ~/.netrc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leafmap.nasa_data_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View NASA Earthdata datasets\n",
    "A tab separated values (TSV) file, made available through the opengeos Github repository, catalogues metadata for more than 9,000 datasets available through NASA Earthdata. In the next cell we load the TSV into a pandas dataframe and view the metadata for the first five (5) Earthdata products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### View Earthdata datasets\n",
    "earthdata_url = 'https://github.com/opengeos/NASA-Earth-Data/raw/main/nasa_earth_data.tsv'\n",
    "earthdata_df = pd.read_csv(earthdata_url, sep='\\t')\n",
    "# earthdata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the available OPERA products\n",
    "Note above that the `earthdata_df` contains a number of columns with metadata about each available product. the `ShortName` column will be used to produce a new dataframe containing only OPERA products. Let's view the available products and their metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opera_df = earthdata_df[earthdata_df['ShortName'].str.contains('OPERA', case=False)]\n",
    "# opera_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an area of interest (AOI) and time period of interest (TOI)\n",
    "Define an area of interest (AOI) for the flood event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell initializes the AOI and TOI.\n",
    "\n",
    "AOI = f_bounds = (-118.179447, 34.182380,-118.164887,  34.208998) #W, S, E, N; This notebook looks at the Arroyo Secco Next to JPL\n",
    "AOI_box = box(*AOI)\n",
    "\n",
    "df_aoi = gpd.GeoDataFrame(geometry=[AOI_box], crs=CRS.from_epsg(4326))\n",
    "\n",
    "# m = df_aoi.exterior.explore()\n",
    "\n",
    "StartDate=\"2023-10-01T00:00:00\"  #image start date\n",
    "EndDate=\"2024-08-30T23:59:59\"    #image end date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Earthdata and return metadata for OPERA products within the AOI\n",
    "The `earthaccess` library makes it simple to quickly query NASA's Common Metadata Repository (CMR) and return the associated metadata as a Geodataframe. `Leafmap` has recently added functionality that builds on `earthaccess` to enable interactive viewing of this data. \n",
    "In the next cell, the user should specify which OPERA product and the date range of interest. The AOI defined previously is used as the boundary in the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View OPERA Product Shortnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print the available OPERA datasets \n",
    "print('Available OPERA datasets:', opera_df['ShortName'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the OPERA DSWx-HLS dataset for the AOI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dswx_results, dswx_gdf = leafmap.nasa_data_search(\n",
    "    short_name='OPERA_L3_DSWX-HLS_V1',\n",
    "    cloud_hosted=True,\n",
    "    bounding_box= AOI,\n",
    "    temporal=(StartDate, EndDate),\n",
    "    count=-1,  # use -1 to return all datasets\n",
    "    return_gdf=True,\n",
    "    # cloud_cover=10,\n",
    "    # bbox_geom=AOI,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dswx_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the available DSWx-HLS layers\n",
    "Functionality within earthaccess enables more more asthetic views of the available layers, as well as displaying the thumbnail. These links are clickable and will download in the browser when clicked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dswx_results[0] #Note this just shows a single MGRS/HLS tile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the DSWx-HLS metadata and footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dswx_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the location of the tiles \n",
    "dswx_gdf.explore(fill=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aoi.explore(fill=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data with leafmap\n",
    "Let's download the data from one of our above queries. In the cell below we specify data from the DSWx-HLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a subdirectory\n",
    "This will be where the files are downloaded. It will be a subdirectory inside of a directory called `data`, and the directory name will be the date that it was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_data_directory():\n",
    "    # Get the current date and time\n",
    "    # current_datetime = datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    current_datetime = datetime.now().strftime(\"%m_%d_%Y\")\n",
    "\n",
    "    # Define the base directory\n",
    "    base_directory = \"data\"\n",
    "\n",
    "    # Create the full path for the new directory\n",
    "    new_directory_path = os.path.join(base_directory, f\"data_{current_datetime}\")\n",
    "    # Create the new directory\n",
    "    os.makedirs(new_directory_path, exist_ok=True)\n",
    "\n",
    "    print(f\"Directory '{new_directory_path}' created successfully.\")\n",
    "\n",
    "    return new_directory_path \n",
    "\n",
    "directory_path = create_data_directory()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "The below will download the data to your newly created subdirectory. Look on your file system for a directory `/data/date/` where `date` is the date the directory was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dswx_data = leafmap.nasa_data_download(dswx_results, out_dir=directory_path)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the files using Leafmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in images from data folder\n",
    "We load in data from only the DSWx-WTR layer below. If you'd like load data from a different layer change the `B01` to suit your needs. \n",
    "Included layers:\n",
    "\n",
    "\n",
    "OPERA_L3_DSWx-HLS_*B01_WTR.tif\n",
    "\n",
    "\n",
    "OPERA_L3_DSWx-HLS_*B02_BWTR.tif\n",
    "\n",
    "\n",
    "OPERA_L3_DSWx-HLS_*B03_CONF.tif\n",
    "\n",
    "\n",
    "OPERA_L3_DSWx-HLS_*B04_DIAG.tif\n",
    "\n",
    "\n",
    "OPERA_L3_DSWx-HLS_*B05_WTR-1.tif\n",
    "\n",
    "\n",
    "OPERA_L3_DSWx-HLS_*B06_WTR-2.tif\n",
    "\n",
    "\n",
    "OPERA_L3_DSWx-HLS_*B07_LAND.tif\n",
    "\n",
    "\n",
    "OPERA_L3_DSWx-HLS_*B08_SHAD.tif\n",
    "\n",
    "\n",
    "OPERA_L3_DSWx-HLS_*B09_CLOUD.tif\n",
    "\n",
    "\n",
    "OPERA_L3_DSWx-HLS_*B10_DEM.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ImageLayer='B01' #B01 corresponds to WTR (see above)\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Construct the path to the data directory\n",
    "data_directory = os.path.join(current_directory, directory_path)\n",
    "\n",
    "# Create a list of file paths and a list of corresponding dates\n",
    "images = [os.path.join(data_directory, filename) for filename in os.listdir(data_directory) if os.path.isfile(os.path.join(data_directory, filename)) and ImageLayer in filename]\n",
    "image_dates = [image[25:33] for image in os.listdir(data_directory) if ImageLayer in image]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge individual tiles into a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_merged='Merged.tif'\n",
    "merged_raster = leafmap.merge_rasters(data_directory,os.path.join(data_directory, filename_merged),input_pattern='*' + ImageLayer +'*.tif',output_format='GTiff',output_nodata=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the merged images\n",
    "##### ***  The Harmonized Landsat Sentinel-2 (HLS) mask layer (Fmask) sometimes misclassifies sediment-laden or white (i.e. turbulent) surface water as Snow/Ice. This is relevant to this Brazil Flood Example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = leafmap.Map(basemap=\"Esri.WorldImagery\")\n",
    "m.add_raster(os.path.join(data_directory, filename_merged), opacity=1,nodata=0)\n",
    "m.zoom_to_bounds(AOI)\n",
    "\n",
    "legend_dict = {\n",
    "    'Not Water': '##ffffff',\n",
    "    'Open Surface Water': '#0000ff',\n",
    "    'Partial Surface Water': '#b4d5f4',\n",
    "    'HLS snow/ice mask': '#00ffff',\n",
    "    'HLS cloud/cloud shadow mask': '#afafaf'\n",
    "}\n",
    "# Add the legend to the map\n",
    "m.add_legend(legend_title=\"Legend Title\", legend_dict=legend_dict)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Images to bbox and filter out clouds and no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(images[0]) as src:\n",
    "    # Print raster metadata\n",
    "    print(\"Metadata:\")\n",
    "    print(src.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.warp import transform_bounds\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "utm_bounds = transform_bounds(CRS.from_epsg(4326), src.crs, *f_bounds)\n",
    "print(utm_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(data_directory, 'cropped')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_raster_to_roi(raster_path, utm_bounds, output_path):\n",
    "    \"\"\"Crop raster to the region of interest (ROI) and save it.\"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Define bounding box from ROI\n",
    "        bbox_geom = box(utm_bounds[0], utm_bounds[1], utm_bounds[2], utm_bounds[3])\n",
    "        bbox_gdf = gpd.GeoDataFrame({'geometry': [bbox_geom]}, crs=src.crs)\n",
    "\n",
    "        # Get the raster's transform and CRS\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "\n",
    "        # Reproject ROI to the raster's CRS\n",
    "        bbox_gdf = bbox_gdf.to_crs(crs)\n",
    "\n",
    "        # Mask the raster using the bounding box\n",
    "        out_image, out_transform = mask(src, bbox_gdf.geometry, crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            'height': out_image.shape[1],\n",
    "            'width': out_image.shape[2],\n",
    "            'transform': out_transform\n",
    "        })\n",
    "\n",
    "        #  # Check for NaN values in the cropped image across all bands\n",
    "        # if np.isnan(out_image).any():\n",
    "        #     print(f'Skipping {os.path.basename(raster_path)} due to NaN values in the cropped area.')\n",
    "        #     return\n",
    "\n",
    "        # Check for NoData values in the cropped image\n",
    "        nodata = src.nodata\n",
    "        if nodata is not None:\n",
    "            total_pixels = out_image.size\n",
    "            nodata_pixels = (out_image == nodata).sum()\n",
    "            nodata_percentage = (nodata_pixels / total_pixels) * 100\n",
    "\n",
    "            if nodata_percentage > 90:\n",
    "                print(f'Skipping {os.path.basename(raster_path)} due to more than 90% NoData values in the cropped area.')\n",
    "                return\n",
    "\n",
    "        # Check for Cloud/Cloud Shadow values in the cropped image\n",
    "        cloud = 253 #cloud pixel values\n",
    "        if cloud is not None:\n",
    "            total_pixels = out_image.size\n",
    "            cloud_pixels = (out_image == cloud).sum()\n",
    "            cloud_percentage = (cloud_pixels / total_pixels) * 100\n",
    "\n",
    "            if cloud_percentage > 50:\n",
    "                print(f'Skipping {os.path.basename(raster_path)} due to more than 50% clouds in the cropped area.')\n",
    "                return\n",
    "\n",
    "        # Save the colormap\n",
    "        colormap = src.colormap(1) if src.count == 1 else None\n",
    "\n",
    "        # Save the cropped raster if no NaN values are found\n",
    "        with rasterio.open(output_path, 'w', **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "            if colormap:\n",
    "                dest.write_colormap(1, colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raster_file in images:\n",
    "    file_name = os.path.basename(raster_file)\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    crop_raster_to_roi(raster_file, utm_bounds, output_path)\n",
    "    if os.path.exists(output_path):\n",
    "        print(f'Cropped and saved {file_name} to {output_path}')\n",
    "    else:\n",
    "        print(f'Skipped {file_name}')\n",
    "\n",
    "print('Processing complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a time lapse (not yet working)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opera_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
